{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9f5e24-0311-4f55-b8e4-4dbdcf9dfc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tarfile\\n\\nwith tarfile.open('fishRecognition_GT.tar', 'r') as tar:\\n    tar.extractall('fish')\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import tarfile\n",
    "\n",
    "with tarfile.open('fishRecognition_GT.tar', 'r') as tar:\n",
    "    tar.extractall('fish')'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b7f16d8-fb6f-487b-b1b0-2c68cab83021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.object = object   \n",
    "np.int = int  \n",
    "np.float = float    \n",
    "np.bool = bool    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f6c528-5a12-4827-8841-47980447839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efb83c9-8946-4e91-af1a-b74fa272e0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2694a54b-1f7b-47ed-bef6-7f5244bbb491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91ebf95-ea59-4f5d-ae63-b3c4c90672bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'path = \"fishaugmentation_fish4knowledge\"\\nprint(os.listdir(path))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'!pip install split-folders'\n",
    "'''import splitfolders\n",
    "import os'''\n",
    "'''path = \"fishaugmentation_fish4knowledge\"\n",
    "print(os.listdir(path))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27971364-fd70-408d-b5f0-2fb38dff5e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"splitfolders.ratio(path,seed=1337,output='fish4knowledge_augmented_output', ratio=(0.8, 0, 0.2))\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''splitfolders.ratio(path,seed=1337,output='fish4knowledge_augmented_output', ratio=(0.8, 0, 0.2))'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14b91ea-af2b-45ed-b923-aae23be3ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d4aa64-49e6-47bf-98f9-a4a64f2e56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2b19abb-f232-4196-92ba-949863fc673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = ResNet50(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "    input_shape=(256,256,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1465f3ea-8d0e-4597-bf05-8cc3a64978f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"set_trainable = False\\n\\nfor layer in conv_base.layers:\\n  if layer.name == 'block5_conv1':\\n    set_trainable = True\\n  if set_trainable:\\n    layer.trainable = True\\n  else:\\n    layer.trainable = False\\n\\nfor layer in conv_base.layers:\\n  print(layer.name,layer.trainable)\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_base.trainable = False\n",
    "\n",
    "'''set_trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  if layer.name == 'block5_conv1':\n",
    "    set_trainable = True\n",
    "  if set_trainable:\n",
    "    layer.trainable = True\n",
    "  else:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in conv_base.layers:\n",
    "  print(layer.name,layer.trainable)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7530073b-c2e7-4133-b8f7-af6e1e414462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b9b8e88-39dc-4e0b-a083-710a1b8acbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "666a4801-fc54-46ce-af19-9e2dedf2c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(23,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d75946a-6da6-48d8-97d8-5127c3e78b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 8, 8, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 131072)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33554688  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 23)                5911      \n",
      "=================================================================\n",
      "Total params: 57,148,311\n",
      "Trainable params: 33,560,599\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d610e70-2a6a-4dfc-aa52-9dbd1a859520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e14d0f83-6b50-4d08-8fd3-d79fe56072d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48887 files belonging to 23 classes.\n",
      "Found 12232 files belonging to 23 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Train dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'fish4knowledge_augmented_output/train',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# Validation dataset\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'fish4knowledge_augmented_output/test',\n",
    "    image_size=(256, 256),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    label_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52813921-b1bf-4475-9ce1-b354630374e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for images, labels in train_dataset:\\n    predictions = model(images)\\n    print(predictions.shape)  # Check the shape of predictions\\n    print(labels.shape)       # Check the shape of labels\\n    break  # Break after one batch for quick inspection'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for images, labels in train_dataset:\n",
    "    predictions = model(images)\n",
    "    print(predictions.shape)  # Check the shape of predictions\n",
    "    print(labels.shape)       # Check the shape of labels\n",
    "    break  # Break after one batch for quick inspection'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7634da2-3330-4a37-8fa9-5416a3426cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03d065c5-9438-45d7-9df5-c27210ae98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "520bd27a-90e9-4cad-956c-58b97d135b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00001,\n",
    "    patience=20,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e716a32b-6811-4b4a-ad95-cf5b264a1f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 12s 213ms/step - loss: 25.8593 - accuracy: 0.2090 - val_loss: 11.3688 - val_accuracy: 0.1777\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 4.1667 - accuracy: 0.3672 - val_loss: 1.9651 - val_accuracy: 0.4922\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 2.3313 - accuracy: 0.3555 - val_loss: 1.0294 - val_accuracy: 0.7422\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 2.0396 - accuracy: 0.4355 - val_loss: 1.5351 - val_accuracy: 0.5625\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 2.0511 - accuracy: 0.4395 - val_loss: 1.0447 - val_accuracy: 0.6855\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.9221 - accuracy: 0.4688 - val_loss: 0.6079 - val_accuracy: 0.8828\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 6s 181ms/step - loss: 1.7751 - accuracy: 0.5352 - val_loss: 0.9530 - val_accuracy: 0.7383\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 6s 182ms/step - loss: 1.6235 - accuracy: 0.5645 - val_loss: 0.3137 - val_accuracy: 0.9219\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 1.4760 - accuracy: 0.5820 - val_loss: 1.0250 - val_accuracy: 0.6973\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 1.4647 - accuracy: 0.5859 - val_loss: 0.4572 - val_accuracy: 0.8809\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 1.4263 - accuracy: 0.5996 - val_loss: 0.7402 - val_accuracy: 0.7871\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.3416 - accuracy: 0.6152 - val_loss: 0.6519 - val_accuracy: 0.8184\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 1.5948 - accuracy: 0.6230 - val_loss: 0.9142 - val_accuracy: 0.6855\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.2936 - accuracy: 0.6367 - val_loss: 0.7918 - val_accuracy: 0.7168\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.4054 - accuracy: 0.6133 - val_loss: 0.5704 - val_accuracy: 0.7773\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 1.3752 - accuracy: 0.6387 - val_loss: 1.5412 - val_accuracy: 0.4961\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 1.2533 - accuracy: 0.6484 - val_loss: 0.2763 - val_accuracy: 0.9082\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 1.1325 - accuracy: 0.6602 - val_loss: 0.4134 - val_accuracy: 0.8828\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 6s 183ms/step - loss: 1.1036 - accuracy: 0.6934 - val_loss: 0.6740 - val_accuracy: 0.8320\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.9823 - accuracy: 0.6992 - val_loss: 0.2918 - val_accuracy: 0.9199\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 1.1212 - accuracy: 0.6934 - val_loss: 0.3072 - val_accuracy: 0.9258\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.0731 - accuracy: 0.6992 - val_loss: 0.1695 - val_accuracy: 0.9473\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 1.1543 - accuracy: 0.6738 - val_loss: 0.5722 - val_accuracy: 0.8281\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.9417 - accuracy: 0.7227 - val_loss: 0.4873 - val_accuracy: 0.8672\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.8850 - accuracy: 0.7539 - val_loss: 0.9878 - val_accuracy: 0.8223\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 1.0642 - accuracy: 0.7012 - val_loss: 0.4612 - val_accuracy: 0.8984\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.9281 - accuracy: 0.7344 - val_loss: 0.4388 - val_accuracy: 0.8438\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.8557 - accuracy: 0.7520 - val_loss: 0.3056 - val_accuracy: 0.9238\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 6s 184ms/step - loss: 0.8751 - accuracy: 0.7441 - val_loss: 0.1412 - val_accuracy: 0.9453\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.8022 - accuracy: 0.7754 - val_loss: 0.4564 - val_accuracy: 0.8418\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.9510 - accuracy: 0.6992 - val_loss: 0.3185 - val_accuracy: 0.9160\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.8946 - accuracy: 0.7480 - val_loss: 0.7122 - val_accuracy: 0.8105\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 0.9059 - accuracy: 0.7031 - val_loss: 0.1602 - val_accuracy: 0.9570\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 6s 200ms/step - loss: 0.8083 - accuracy: 0.7754 - val_loss: 0.2392 - val_accuracy: 0.9395\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 0.8512 - accuracy: 0.7598 - val_loss: 0.0614 - val_accuracy: 0.9805\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 6s 201ms/step - loss: 0.7767 - accuracy: 0.7598 - val_loss: 0.1989 - val_accuracy: 0.9395\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.6733 - accuracy: 0.8086 - val_loss: 1.0846 - val_accuracy: 0.6992\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 1.0535 - accuracy: 0.7168 - val_loss: 0.6467 - val_accuracy: 0.8223\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.9206 - accuracy: 0.7402 - val_loss: 0.5058 - val_accuracy: 0.8359\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.8307 - accuracy: 0.7832 - val_loss: 0.6186 - val_accuracy: 0.8125\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.8500 - accuracy: 0.7480 - val_loss: 0.2802 - val_accuracy: 0.9316\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.6978 - accuracy: 0.8203 - val_loss: 0.1010 - val_accuracy: 0.9688\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 0.8678 - accuracy: 0.7891 - val_loss: 0.1545 - val_accuracy: 0.9473\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 0.7150 - accuracy: 0.8203 - val_loss: 0.2193 - val_accuracy: 0.9004\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.6018 - accuracy: 0.8281 - val_loss: 0.5104 - val_accuracy: 0.8457\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.6150 - accuracy: 0.8301 - val_loss: 0.1693 - val_accuracy: 0.9375\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.6603 - accuracy: 0.8262 - val_loss: 0.3594 - val_accuracy: 0.8828\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.6753 - accuracy: 0.8008 - val_loss: 0.1372 - val_accuracy: 0.9629\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 6s 194ms/step - loss: 0.6757 - accuracy: 0.8242 - val_loss: 0.3673 - val_accuracy: 0.8789\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.5883 - accuracy: 0.8281 - val_loss: 0.5374 - val_accuracy: 0.8652\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.6889 - accuracy: 0.8027 - val_loss: 0.0801 - val_accuracy: 0.9785\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.5829 - accuracy: 0.8398 - val_loss: 0.0751 - val_accuracy: 0.9785\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.6213 - accuracy: 0.8398 - val_loss: 0.6588 - val_accuracy: 0.8613\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.6163 - accuracy: 0.8496 - val_loss: 0.2365 - val_accuracy: 0.9316\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.5987 - accuracy: 0.8125 - val_loss: 0.8931 - val_accuracy: 0.7949\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.7796 - accuracy: 0.7891 - val_loss: 0.3110 - val_accuracy: 0.9102\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.5918 - accuracy: 0.8379 - val_loss: 0.2655 - val_accuracy: 0.9395\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.5658 - accuracy: 0.8418 - val_loss: 0.2568 - val_accuracy: 0.9297\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.6413 - accuracy: 0.8164 - val_loss: 0.2647 - val_accuracy: 0.9121\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.5692 - accuracy: 0.8438 - val_loss: 0.4687 - val_accuracy: 0.8340\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.5461 - accuracy: 0.8555 - val_loss: 0.1704 - val_accuracy: 0.9570\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.5784 - accuracy: 0.8301 - val_loss: 0.2537 - val_accuracy: 0.9316\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.5163 - accuracy: 0.8477 - val_loss: 0.3263 - val_accuracy: 0.8672\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.5709 - accuracy: 0.8359 - val_loss: 0.4846 - val_accuracy: 0.8633\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.4721 - accuracy: 0.8613 - val_loss: 0.1684 - val_accuracy: 0.9570\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.5702 - accuracy: 0.8750 - val_loss: 0.0760 - val_accuracy: 0.9785\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.6926 - accuracy: 0.8359 - val_loss: 0.8316 - val_accuracy: 0.7520\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.5394 - accuracy: 0.8223 - val_loss: 0.1238 - val_accuracy: 0.9727\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.5992 - accuracy: 0.8438 - val_loss: 0.0763 - val_accuracy: 0.9746\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.5458 - accuracy: 0.8340 - val_loss: 0.2804 - val_accuracy: 0.9375\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.6733 - accuracy: 0.8535 - val_loss: 0.8928 - val_accuracy: 0.6641\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.4157 - accuracy: 0.8516 - val_loss: 0.1646 - val_accuracy: 0.9531\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.6165 - accuracy: 0.8359 - val_loss: 0.3146 - val_accuracy: 0.9258\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.4827 - accuracy: 0.8574 - val_loss: 0.0781 - val_accuracy: 0.9805\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.5116 - accuracy: 0.8906 - val_loss: 0.2891 - val_accuracy: 0.9121\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4027 - accuracy: 0.8848 - val_loss: 0.2187 - val_accuracy: 0.9434\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.5771 - accuracy: 0.8438 - val_loss: 0.5419 - val_accuracy: 0.8164\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 6s 196ms/step - loss: 0.5089 - accuracy: 0.8555 - val_loss: 0.2834 - val_accuracy: 0.9258\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 6s 195ms/step - loss: 0.4490 - accuracy: 0.8633 - val_loss: 0.5209 - val_accuracy: 0.8496\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4713 - accuracy: 0.8691 - val_loss: 0.0929 - val_accuracy: 0.9727\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4021 - accuracy: 0.8691 - val_loss: 0.1866 - val_accuracy: 0.9414\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.4940 - accuracy: 0.8750 - val_loss: 0.0700 - val_accuracy: 0.9785\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 6s 186ms/step - loss: 0.4192 - accuracy: 0.8691 - val_loss: 0.2404 - val_accuracy: 0.9180\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 0.6169 - accuracy: 0.8418 - val_loss: 0.5205 - val_accuracy: 0.8789\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 6s 188ms/step - loss: 0.5330 - accuracy: 0.8730 - val_loss: 0.4096 - val_accuracy: 0.9297\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4987 - accuracy: 0.8613 - val_loss: 0.1139 - val_accuracy: 0.9551\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 6s 193ms/step - loss: 0.5921 - accuracy: 0.8574 - val_loss: 0.1541 - val_accuracy: 0.9473\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 6s 189ms/step - loss: 0.4875 - accuracy: 0.8672 - val_loss: 0.1327 - val_accuracy: 0.9609\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 6s 187ms/step - loss: 0.3608 - accuracy: 0.8809 - val_loss: 0.2548 - val_accuracy: 0.9258\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4904 - accuracy: 0.8711 - val_loss: 0.1498 - val_accuracy: 0.9590\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 6s 185ms/step - loss: 0.5707 - accuracy: 0.8516 - val_loss: 0.3208 - val_accuracy: 0.9277\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 6s 197ms/step - loss: 0.4651 - accuracy: 0.8828 - val_loss: 0.0991 - val_accuracy: 0.9707\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 6s 192ms/step - loss: 0.5124 - accuracy: 0.8633 - val_loss: 0.1022 - val_accuracy: 0.9707\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 6s 191ms/step - loss: 0.3889 - accuracy: 0.8789 - val_loss: 0.1169 - val_accuracy: 0.9746\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 6s 190ms/step - loss: 0.4842 - accuracy: 0.8789 - val_loss: 0.2553 - val_accuracy: 0.9434\n",
      "Epoch 96/100\n",
      "16/32 [==============>...............] - ETA: 2s - loss: 0.3905 - accuracy: 0.8947WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3200 batches). You may need to use the repeat() function when building your dataset.\n",
      "32/32 [==============================] - 5s 172ms/step - loss: 0.3905 - accuracy: 0.8947 - val_loss: 0.2687 - val_accuracy: 0.9395\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset,steps_per_epoch=32,epochs=100,validation_data=validation_dataset,validation_steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b4f32-beb2-46bd-97cd-b45c037f8105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'!pip install opencv-python'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711ea53-4216-4d58-9d6e-81f10de79f34",
   "metadata": {},
   "outputs": [],
   "source": [
    " import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'],color='red',label='train')\n",
    "plt.plot(history.history['val_accuracy'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53a71b-28e4-41e0-bf74-678fdd564614",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],color='red',label='train')\n",
    "plt.plot(history.history['val_loss'],color='blue',label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2844f11c-be49-41b5-879e-c2e105cc7f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323a6952-fbd2-40f8-a749-c4bbe0d6ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.imread('fish1new2.png')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf68f6-3ab0-4877-b2c7-22207ee3759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f114a4-a9d6-4f92-933b-fea2932eae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf05302-6e67-4cf9-9d27-fc3704ad2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.resize(test_img,(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ef91a-acfe-46ce-bc32-7d6b04c12496",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc51e377-1f22-4d72-9dd3-a2cdf777dafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_img.reshape((1,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914c305-fa21-4e7c-987a-d320b57d5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f02c92-6b32-4b4c-bc01-2fdb36f523f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(test_input),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4b7fca-a39c-44d3-ad6b-9b81fa8c138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29d686-7d84-455e-ba50-dc54ce57cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bd35fb-b0d3-46c2-9850-adf5a94c6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import cv2\n",
    "import os\n",
    "\n",
    "def find_max_image_shape(directory):\n",
    "    max_width, max_height = 0, 0\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "            # Construct the full file path\n",
    "            filepath = os.path.join(directory, filename)\n",
    "\n",
    "            # Read the image\n",
    "            img = cv2.imread(filepath)\n",
    "\n",
    "            # Get the shape of the image\n",
    "            height, width, _ = img.shape\n",
    "\n",
    "            # Update max width and height if needed\n",
    "            max_width = max(max_width, width)\n",
    "            max_height = max(max_height, height)\n",
    "\n",
    "    return max_width, max_height\n",
    "\n",
    "# Provide the path to your dataset directory\n",
    "dataset_directory = \"fish project/fish/fish_image/fish_01\"\n",
    "\n",
    "# Call the function to find the maximum image shape\n",
    "max_width, max_height = find_max_image_shape(dataset_directory)\n",
    "\n",
    "print(\"Maximum Image Width:\", max_width)\n",
    "print(\"Maximum Image Height:\", max_height)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91996ec1-be08-4579-9cc1-9896d7930e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size - padding \n",
    "# data augmnetation \n",
    "# fine tunning \n",
    "# multi layer API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc865a56-25d8-4251-9517-29f55f3eeca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up the directories\n",
    "input_dir = 'fish/fish_image/fish_23'\n",
    "output_dir = 'fishaugmentation_fish4knowledge/fish23'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,# Normalize pixel values to the range [0, 1]\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "# Load each image in the input directory and generate augmented images\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        img = image.load_img(img_path)\n",
    "        x = image.img_to_array(img)\n",
    "        x = x.reshape((1,) + x.shape)\n",
    "\n",
    "        # Generate augmented images and save to the output directory\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1, save_to_dir=output_dir, save_prefix='aug', save_format='jpeg'):\n",
    "            i += 1\n",
    "            if i >= 120:  # Generate 5 augmented images for each original image\n",
    "                break\n",
    "\n",
    "# Display one original and augmented image for verification\n",
    "original_img = image.load_img(os.path.join(input_dir, os.listdir(input_dir)[0]))\n",
    "augmented_img = image.load_img(os.path.join(output_dir, os.listdir(output_dir)[0]))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_img)\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(augmented_img)\n",
    "plt.title('Augmented Image')\n",
    "\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e01a8-a91e-4c03-a76b-9ee74bcd37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import os\n",
    "\n",
    "augmented_folder = 'fishaugmentation_fish4knowledge/fish23'  # Replace with your folder path\n",
    "\n",
    "image_count = 0\n",
    "for root, _, files in os.walk(augmented_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(('.jpg', '.jpeg', '.png')):  # Adjust for other image extensions if needed\n",
    "            image_count += 1\n",
    "\n",
    "print(\"Number of images in the augmented folder:\", image_count)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56edd2-3b3b-4d62-8037-24322e5a8261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
